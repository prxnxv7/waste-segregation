{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO \n",
    "import serial, time\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your VGG16 waste classification model\n",
    "model_classification = load_model('vgg16_biodegradable_classifier_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLO model\n",
    "model_yolo = YOLO('yolov8n.pt')\n",
    "# object classes\n",
    "classNames = model_yolo.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for waste classification\n",
    "def classify_waste(object_image):\n",
    "    # Resize the object image to match your VGG16 input size\n",
    "    resized_img = cv2.resize(object_image, (60, 60))\n",
    "    # Expand dimensions to make it compatible with the model\n",
    "    resized_img = np.expand_dims(resized_img, axis=0)\n",
    "    # Perform classification\n",
    "    prediction = model_classification.predict(resized_img)\n",
    "    # Convert prediction to label\n",
    "    label = np.argmax(prediction)\n",
    "    # Map label to waste type\n",
    "    if label == 0:\n",
    "        return \"biodegradable\"\n",
    "    else:\n",
    "        return \"non-biodegradable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 179.9ms\n",
      "Speed: 5.6ms preprocess, 179.9ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 138.7ms\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Arduino response: \n",
      "Speed: 0.0ms preprocess, 138.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 134.6ms\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Speed: 2.9ms preprocess, 134.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 135.0ms\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Arduino response: \n",
      "Speed: 3.6ms preprocess, 135.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 130.2ms\n",
      "Speed: 0.0ms preprocess, 130.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 130.4ms\n",
      "Speed: 3.0ms preprocess, 130.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 132.1ms\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Arduino response: \n",
      "Speed: 6.0ms preprocess, 132.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Establish serial communication with Arduino\n",
    "arduino = serial.Serial('COM3', 9600, timeout=1)  # Replace 'COM3' with the appropriate port\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "last_prediction = None\n",
    "last_frame_sent_time = 0\n",
    "frame_interval = 5  # in seconds\n",
    "\n",
    "while True:\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Send frame only if 5 seconds have passed since the last frame sent\n",
    "    if current_time - last_frame_sent_time >= frame_interval:\n",
    "        success, img = cap.read()\n",
    "        if success:\n",
    "            results = model_yolo(img, stream=True)\n",
    "\n",
    "            for r in results:\n",
    "                boxes = r.boxes\n",
    "\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                    cropped_object = img[int(y1):int(y2), int(x1):int(x2)]\n",
    "                    waste_type = classify_waste(cropped_object)\n",
    "\n",
    "                    if last_prediction != waste_type:\n",
    "                        last_prediction = waste_type\n",
    "\n",
    "                        # Send waste type to Arduino\n",
    "                        if waste_type == \"biodegradable\":\n",
    "                            arduino.write(b'B')  # Signal for biodegradable waste\n",
    "                        else:\n",
    "                            arduino.write(b'N')  # Signal for non-biodegradable waste\n",
    "\n",
    "                        # Read response from Arduino\n",
    "                        response = arduino.readline().decode().strip()\n",
    "                        print(\"Arduino response:\", response)\n",
    "\n",
    "                    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "                    cv2.putText(img, waste_type, (int(x1), int(y1) - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow('Webcam', img)\n",
    "            last_frame_sent_time = current_time\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
